<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"carryliu666.github.io","root":"/","scheme":"Pisces","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="这次的任务:  使用SSD框架进行手部的实时追踪.记录的目的: TensorFlow由于版本更新过快且各个版本的兼容性过差,再加上相关组件(如object detection api以及CUDA&#x2F;duDNN的版本搭配问题)版本对应的要求过高,  导致项目环境搭建要求十分的严格,容易走很多弯路, 这次记录便于日后不再重蹈覆辙 环境的搭建说明:笔记本配置是i5 7代,显卡GTX1066(支持CUDA)">
<meta property="og:type" content="article">
<meta property="og:title" content="HandDetectoin实战">
<meta property="og:url" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/index.html">
<meta property="og:site_name" content="瑞酱学习之路">
<meta property="og:description" content="这次的任务:  使用SSD框架进行手部的实时追踪.记录的目的: TensorFlow由于版本更新过快且各个版本的兼容性过差,再加上相关组件(如object detection api以及CUDA&#x2F;duDNN的版本搭配问题)版本对应的要求过高,  导致项目环境搭建要求十分的严格,容易走很多弯路, 这次记录便于日后不再重蹈覆辙 环境的搭建说明:笔记本配置是i5 7代,显卡GTX1066(支持CUDA)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-1853c607.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-ad5310e4.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-dc407f83.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-4e4a1d7e.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-1074e678.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-73e1304d.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-26cc28fb.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-28793dde.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-82f86d9b.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-b3796b78.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-4141edfd.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-baad123a.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-c86cf67b.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-77743612.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-e32d6252.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-22b11a70.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-f7f25029.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-62f78caa.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-2e9d6f7d.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-21dfe2b5.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-28141ed8.png">
<meta property="og:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-202668c9.png">
<meta property="article:published_time" content="2020-03-19T06:49:04.000Z">
<meta property="article:modified_time" content="2020-03-28T06:17:53.570Z">
<meta property="article:author" content="Liu Kairui">
<meta property="article:tag" content="Pytorch">
<meta property="article:tag" content="动态手势">
<meta property="article:tag" content="机器视觉">
<meta property="article:tag" content="SSD">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-1853c607.png">

<link rel="canonical" href="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>HandDetectoin实战 | 瑞酱学习之路</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">瑞酱学习之路</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://carryliu666.github.io/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.png">
      <meta itemprop="name" content="Liu Kairui">
      <meta itemprop="description" content="tmd给我往死里学">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="瑞酱学习之路">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          HandDetectoin实战
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-19 14:49:04" itemprop="dateCreated datePublished" datetime="2020-03-19T14:49:04+08:00">2020-03-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-28 14:17:53" itemprop="dateModified" datetime="2020-03-28T14:17:53+08:00">2020-03-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%82%8C%E7%94%B5/" itemprop="url" rel="index"><span itemprop="name">肌电</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%82%8C%E7%94%B5/%E5%8A%A8%E6%80%81%E6%89%8B%E5%8A%BF/" itemprop="url" rel="index"><span itemprop="name">动态手势</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>这次的任务:  使用SSD框架进行手部的实时追踪.<br>记录的目的: TensorFlow由于版本更新过快且各个版本的兼容性过差,再加上相关组件(如object detection api以及CUDA/duDNN的版本搭配问题)版本对应的要求过高,  导致项目环境搭建要求十分的严格,容易走很多弯路, 这次记录便于日后不再重蹈覆辙</p>
<h3 id="环境的搭建"><a href="#环境的搭建" class="headerlink" title="环境的搭建"></a>环境的搭建</h3><p>说明:笔记本配置是i5 7代,显卡GTX1066(支持CUDA),windows10.</p>
<h3 id="tensorflow与CUDA-cuDNN版本对应表"><a href="#tensorflow与CUDA-cuDNN版本对应表" class="headerlink" title="tensorflow与CUDA/cuDNN版本对应表"></a>tensorflow与CUDA/cuDNN版本对应表</h3><p><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-1853c607.png" alt></p>
<h3 id="要配置的环境-教程里的旧版环境"><a href="#要配置的环境-教程里的旧版环境" class="headerlink" title="要配置的环境(教程里的旧版环境)"></a>要配置的环境(教程里的旧版环境)</h3><ol>
<li><p>anaconda3(64位);下个新的就好了.</p>
</li>
<li><p>python3.6;anaconda里面设一个python3.6的环境就好了.</p>
</li>
<li><p>CUDA-9.1; 下载地址<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a> 安装完后下载下面的(<strong>会自动添加环境变量</strong>)</p>
</li>
<li><p>CuDNN-7.0.5;下载地址<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a> ，在下载CUDNN7.0.5之前，需要登录NVIDIA账号，没有的话要注册登录后才能下载. <strong>注意添加环境变量</strong></p>
</li>
<li><p>TensorFlow-gpu(1.4.0版本):从网站:<a href="https://github.com/fo40225/tensorflow-windows-wheel" target="_blank" rel="noopener">https://github.com/fo40225/tensorflow-windows-wheel</a> 下载特定版本的whl文件,之后在conda环境里用(比如)<code>pip install tensorflow_gpu-1.4.0-cp36-cp36m-win_amd64.whl</code></p>
</li>
<li><p>object detection api 选择r1.4.0 branch 再 git clone,之后安装起来并验证是否成功安装<code>python object_detection/builders/model_builder_test.py</code></p>
</li>
</ol>
<h4 id="我的最终新环境"><a href="#我的最终新环境" class="headerlink" title="我的最终新环境:"></a>我的最终新环境:</h4><ol>
<li><p>anaconda3(64位);下个新的就好了.</p>
</li>
<li><p>python3.7;anaconda里面设一个python3.7的环境就好了.</p>
</li>
<li><p>CUDA10.1+cuDNN7.6;</p>
</li>
<li><p>tensorflow2.1;</p>
</li>
<li><p>object detection api; 参考<a href="https://www.youtube.com/watch?v=qDm_YOwP2zY" target="_blank" rel="noopener">https://www.youtube.com/watch?v=qDm_YOwP2zY</a><br>安装完后cd到models-master\research目录使用<br><code>python object_detection/builders/model_builder_test.py</code> (新版TF2会失败)</p>
</li>
</ol>
<h3 id="需要学习的技能"><a href="#需要学习的技能" class="headerlink" title="需要学习的技能"></a>需要学习的技能</h3><ol>
<li>TensorFlow’s Object Detector API</li>
</ol>
<h3 id="对egohands数据集的介绍和工作"><a href="#对egohands数据集的介绍和工作" class="headerlink" title="对egohands数据集的介绍和工作"></a>对egohands数据集的介绍和工作</h3><p>&ensp;&ensp;&ensp;&ensp;首先egohands数据集里有48个不同场景的文件夹,每个文件夹有100张图片,每张图片的手部都进行了标注,每个图片分别有四个label,分别是 myleft,myright,yourleft,yourright.对应我和你的四只手是否有出现.对于出现的手进行了标注,根据 <a href="https://github.com/victordibia/handtracking" target="_blank" rel="noopener">https://github.com/victordibia/handtracking</a> 提供的工具,成功实现了(第一次用的四个,发生了点问题,这次用单个试试)单个类别的mat to csv.</p>
<p>接下来使用<code>generate_tfrecord.py</code>文件将csv转成tfrecord格式,使用命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python generate_tfrecord.py --csv_input&#x3D;images&#x2F;train_labels.csv  --output_path&#x3D;data&#x2F;train.record</span><br><span class="line">python generate_tfrecord.py --csv_input&#x3D;images&#x2F;test_labels.csv  --output_path&#x3D;data&#x2F;test.record</span><br></pre></td></tr></table></figure>
<p>( 指导视频:<a href="https://pythonprogramming.net/creating-tfrecord-files-tensorflow-object-detection-api-tutorial/" target="_blank" rel="noopener">https://pythonprogramming.net/creating-tfrecord-files-tensorflow-object-detection-api-tutorial/</a> )</p>
<h3 id="训练模型前的准备"><a href="#训练模型前的准备" class="headerlink" title="训练模型前的准备"></a>训练模型前的准备</h3><p>训练自己的模型or使用迁移学习拿别的数据集的网络模型进行参数训练,我选择了后者,并选择使用GPU训练,因为运算速度比cpu快太多</p>
<ol>
<li><p>我选择了ssd_mobilenet_v2_coco</p>
</li>
<li><p>根据要求修改ssd_mobilenet_v2_coco.config. 由于我CPU和内存配置不好,参数设到了最低.</p>
</li>
<li><p>~~放入object_detection进行模型训练.</p>
</li>
</ol>
<h4 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h4><p>首先因为事先训练好的模型是TF1.12版本的,要用的话先用TF1.15 export一下以兼容版本:参考 <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python export_inference_graph.py --input_type&#x3D;image_tensor --pipeline_config_path&#x3D;training&#x2F;ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix&#x3D;ssdmobilenetv1_download&#x2F;model.ckpt-200002 --output_directory&#x3D;ssdmo_v1_1class_inference_graph</span><br></pre></td></tr></table></figure>

<h4 id="使用main-py"><a href="#使用main-py" class="headerlink" title="使用main.py"></a>使用main.py</h4><p>将训练的东西丢进object_detection目录下,首先进入object_detection目录下<br>   <code>cd c:\models-master\research\object_detection</code>使用model_main.py进行训练,方法如下<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python model_main.py --pipeline_config_path&#x3D;training&#x2F;ssd_mobilenet_v2_coco.config --model_dir&#x3D;training&#x2F; --num_train_steps&#x3D;60000 --sample_1_of_n_eval_examples&#x3D;1  --alsologtostderr</span><br></pre></td></tr></table></figure></p>
<p>或者进入legacy目录使用老板的train.py<code>python legacy/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v2_coco.config</code><br>之后风扇开始狂转, 硬件也在高速运转<br>我这i5性能太烂了只能将batchsize设置为1才能训练, 不然就卡死.</p>
<p><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-ad5310e4.png" alt></p>
<p>接下来就可以打开另一个命令窗口cd到object_detection目录使用<br><code>tensorboard --logdir=training</code> 再去浏览器打开<code>http://localhost:6006</code>就可以查看训练的情况啦</p>
<p><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-dc407f83.png" alt></p>
<h4 id="训练的同时进行评估"><a href="#训练的同时进行评估" class="headerlink" title="训练的同时进行评估:"></a>训练的同时进行评估:</h4><p>在legacy目录下使用<code>eval.py</code>,可以看到训练时对模型性能的评估</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python legacy&#x2F;eval.py --logtostderr --eval_dir&#x3D;evalpath&#x2F; --pipeline_config_path&#x3D;training&#x2F;ssd_mobilenet_v2_coco.config --checkpoint_dir&#x3D;training&#x2F;</span><br></pre></td></tr></table></figure>

<h4 id="导出训练好的模型"><a href="#导出训练好的模型" class="headerlink" title="导出训练好的模型:"></a>导出训练好的模型:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python export_inference_graph.py --input_type&#x3D;image_tensor --pipeline_config_path&#x3D;training&#x2F;ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix&#x3D;ssdmobilenetv1_download&#x2F;model.ckpt-200002 --output_directory&#x3D;ssdmo_v1_1class_inference_graph</span><br></pre></td></tr></table></figure>
<p>在ssdmo_v1_1class_inference_graph目录下生成了保存好的网络模型</p>
<p><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-4e4a1d7e.png" alt></p>
<h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><p>接下里开始测试训练的效果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> six.moves.urllib <span class="keyword">as</span> urllib</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># Import the object detection module.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> ops <span class="keyword">as</span> utils_ops</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"></span><br><span class="line"><span class="comment"># patch tf1 into `utils.ops`</span></span><br><span class="line">utils_ops.tf = tf.compat.v1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Patch the location of gfile</span></span><br><span class="line">tf.gfile = tf.io.gfile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># List of the strings that is used to add correct label for each box.</span></span><br><span class="line">PATH_TO_LABELS = <span class="string">'training/object_detection.pbtxt'</span></span><br><span class="line">category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model_name='ssdmo_v1_1class_inference_graph'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_model</span><span class="params">(model_name)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Maybe a problem will ocur because belowed "saved_model"</span></span><br><span class="line">  <span class="comment"># Dont know "saved_model" point to the dir or saved_model.pb</span></span><br><span class="line">  model_dir = pathlib.Path(model_name)/<span class="string">"saved_model"</span></span><br><span class="line"></span><br><span class="line">  model = tf.saved_model.load(str(model_dir))</span><br><span class="line">  model = model.signatures[<span class="string">'serving_default'</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.</span></span><br><span class="line">PATH_TO_TEST_IMAGES_DIR = pathlib.Path(<span class="string">'test_images/'</span>)</span><br><span class="line">TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(<span class="string">"*.jpg"</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># if __name__ == '__main__':</span></span><br><span class="line"></span><br><span class="line">model_name=<span class="string">'ssdmo_v1_1class_inference_graph'</span></span><br><span class="line">detection_model =load_model(model_name)</span><br><span class="line">print(detection_model.inputs)</span><br><span class="line">print(detection_model.output_dtypes)</span><br><span class="line">print(detection_model.output_shapes)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_inference_for_single_image</span><span class="params">(model, image)</span>:</span></span><br><span class="line">    image = np.asarray(image)</span><br><span class="line">    <span class="comment"># The input needs to be a tensor, convert it using `tf.convert_to_tensor`.</span></span><br><span class="line">    input_tensor = tf.convert_to_tensor(image)</span><br><span class="line">    <span class="comment"># The model expects a batch of images, so add an axis with `tf.newaxis`.</span></span><br><span class="line">    input_tensor = input_tensor[tf.newaxis, ...]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run inference</span></span><br><span class="line">    output_dict = model(input_tensor)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># All outputs are batches tensors.</span></span><br><span class="line">    <span class="comment"># Convert to numpy arrays, and take index [0] to remove the batch dimension.</span></span><br><span class="line">    <span class="comment"># We're only interested in the first num_detections.</span></span><br><span class="line">    num_detections = int(output_dict.pop(<span class="string">'num_detections'</span>))</span><br><span class="line">    output_dict = &#123;key: value[<span class="number">0</span>, :num_detections].numpy()</span><br><span class="line">                   <span class="keyword">for</span> key, value <span class="keyword">in</span> output_dict.items()&#125;</span><br><span class="line">    output_dict[<span class="string">'num_detections'</span>] = num_detections</span><br><span class="line"></span><br><span class="line">    <span class="comment"># detection_classes should be ints.</span></span><br><span class="line">    output_dict[<span class="string">'detection_classes'</span>] = output_dict[<span class="string">'detection_classes'</span>].astype(np.int64)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Handle models with masks:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'detection_masks'</span> <span class="keyword">in</span> output_dict:</span><br><span class="line">      <span class="comment"># Reframe the the bbox mask to the image size.</span></span><br><span class="line">      detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(</span><br><span class="line">        output_dict[<span class="string">'detection_masks'</span>], output_dict[<span class="string">'detection_boxes'</span>],</span><br><span class="line">        image.shape[<span class="number">0</span>], image.shape[<span class="number">1</span>])</span><br><span class="line">      detection_masks_reframed = tf.cast(detection_masks_reframed &gt; <span class="number">0.5</span>,</span><br><span class="line">                                         tf.uint8)</span><br><span class="line">      output_dict[<span class="string">'detection_masks_reframed'</span>] = detection_masks_reframed.numpy()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output_dict</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_inference</span><span class="params">(model, image_path)</span>:</span></span><br><span class="line">  <span class="comment"># the array based representation of the image will be used later in order to prepare the</span></span><br><span class="line">  <span class="comment"># result image with boxes and labels on it.</span></span><br><span class="line">  image_np = np.array(Image.open(image_path))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Actual detection.</span></span><br><span class="line">  output_dict = run_inference_for_single_image(model, image_np)</span><br><span class="line">  <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">  vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">      image_np,</span><br><span class="line">      output_dict[<span class="string">'detection_boxes'</span>],</span><br><span class="line">      output_dict[<span class="string">'detection_classes'</span>],</span><br><span class="line">      output_dict[<span class="string">'detection_scores'</span>],</span><br><span class="line">      category_index,</span><br><span class="line">      instance_masks=output_dict.get(<span class="string">'detection_masks_reframed'</span>, <span class="literal">None</span>),</span><br><span class="line">      use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">      line_thickness=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">  plt.imshow(Image.fromarray(image_np))</span><br><span class="line">  plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_path <span class="keyword">in</span> TEST_IMAGE_PATHS:</span><br><span class="line">  show_inference(detection_model, image_path)</span><br></pre></td></tr></table></figure>

<ol>
<li>将训练好的模型导入;</li>
<li>测试并画出识别框default box;</li>
</ol>
<h4 id="进行测试的图片"><a href="#进行测试的图片" class="headerlink" title="进行测试的图片:"></a>进行测试的图片:</h4><p>网上随便找了几个分辨率参差不齐的手部图片,进行测试<br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-1074e678.png" alt></p>
<h4 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h4><p>设定了70%置信度以上的识别框才会描绘出来.<br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-73e1304d.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-26cc28fb.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-28793dde.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-82f86d9b.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-b3796b78.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-4141edfd.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-baad123a.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-c86cf67b.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-77743612.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-e32d6252.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-22b11a70.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-f7f25029.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-62f78caa.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-2e9d6f7d.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-21dfe2b5.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-28141ed8.png" alt><br><img src="/2020/03/19/HandDetectoin%E5%AE%9E%E6%88%98/HandDetectoin%E5%AE%9E%E6%88%98-202668c9.png" alt></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ol>
<li>对于低分辨率切手部较小的图片识别效果比较差,这可能是因为SSD模型首先将图片变成300x300,输入分辨率过低相当于拉伸了图片,比较影响识别准确率.分辨率和训练集一样的那些图片效果比较好.</li>
<li>部分训练集的标注有误,我没一一修改</li>
<li>手势的灰度图片识别能力不怎么样</li>
<li>训练集两方手的位置都比较固定(远近位置和拍摄位置)是影响泛化能力的因素之一</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
              <a href="/tags/%E5%8A%A8%E6%80%81%E6%89%8B%E5%8A%BF/" rel="tag"># 动态手势</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/" rel="tag"># 机器视觉</a>
              <a href="/tags/SSD/" rel="tag"># SSD</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/18/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%8403-%E5%A0%86%E6%A0%88/" rel="prev" title="数据结构03-堆栈">
      <i class="fa fa-chevron-left"></i> 数据结构03-堆栈
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/23/%E6%9D%82%E9%A1%B9%E4%BD%93%E9%AA%8C/" rel="next" title="杂项体验">
      杂项体验 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#环境的搭建"><span class="nav-number">1.</span> <span class="nav-text">环境的搭建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#tensorflow与CUDA-cuDNN版本对应表"><span class="nav-number">2.</span> <span class="nav-text">tensorflow与CUDA&#x2F;cuDNN版本对应表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#要配置的环境-教程里的旧版环境"><span class="nav-number">3.</span> <span class="nav-text">要配置的环境(教程里的旧版环境)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#我的最终新环境"><span class="nav-number">3.1.</span> <span class="nav-text">我的最终新环境:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#需要学习的技能"><span class="nav-number">4.</span> <span class="nav-text">需要学习的技能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对egohands数据集的介绍和工作"><span class="nav-number">5.</span> <span class="nav-text">对egohands数据集的介绍和工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练模型前的准备"><span class="nav-number">6.</span> <span class="nav-text">训练模型前的准备</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#开始训练"><span class="nav-number">6.1.</span> <span class="nav-text">开始训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用main-py"><span class="nav-number">6.2.</span> <span class="nav-text">使用main.py</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#训练的同时进行评估"><span class="nav-number">6.3.</span> <span class="nav-text">训练的同时进行评估:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#导出训练好的模型"><span class="nav-number">6.4.</span> <span class="nav-text">导出训练好的模型:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试模型"><span class="nav-number">7.</span> <span class="nav-text">测试模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#进行测试的图片"><span class="nav-number">7.1.</span> <span class="nav-text">进行测试的图片:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#测试结果"><span class="nav-number">7.2.</span> <span class="nav-text">测试结果</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#总结"><span class="nav-number">7.3.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Liu Kairui"
      src="/uploads/avatar.png">
  <p class="site-author-name" itemprop="name">Liu Kairui</p>
  <div class="site-description" itemprop="description">tmd给我往死里学</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liu Kairui</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
